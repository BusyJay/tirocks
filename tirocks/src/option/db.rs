// Copyright 2022 TiKV Project Authors. Licensed under Apache-2.0.

use std::{os::unix::prelude::OsStrExt, path::Path, sync::Arc, time::Duration};
use tirocks_sys::{r, rocksdb_DBOptions};

use crate::{
    env::{
        logger::{LogLevel, SysInfoLogger},
        Env,
    },
    listener::SysEventListener,
    rate_limiter::RateLimiter,
    Statistics,
};

pub type AccessHint = tirocks_sys::rocksdb_DBOptions_AccessHint;
pub type WalRecoveryMode = tirocks_sys::rocksdb_WALRecoveryMode;

#[derive(Debug)]
pub struct DbOptions {
    ptr: *mut rocksdb_DBOptions,
    env: Option<Arc<Env>>,
}

impl Default for DbOptions {
    #[inline]
    fn default() -> DbOptions {
        let ptr = unsafe { tirocks_sys::crocksdb_dboptions_create() };
        DbOptions { ptr, env: None }
    }
}

impl Drop for DbOptions {
    #[inline]
    fn drop(&mut self) {
        unsafe { tirocks_sys::crocksdb_dboptions_destroy(self.ptr) }
    }
}

impl DbOptions {
    /// If true, the database will be created if it is missing.
    /// Default: false
    #[inline]
    pub fn set_create_if_missing(&mut self, create_if_missing: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_create_if_missing(self.ptr, create_if_missing as _);
        }
        self
    }

    /// If true, missing column families will be automatically created.
    /// Default: false
    #[inline]
    pub fn set_create_missing_column_families(&mut self, create_if_missing: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_create_missing_column_families(
                self.ptr,
                create_if_missing as _,
            );
        }
        self
    }

    /// If true, an error is raised if the database already exists.
    /// Default: false
    #[inline]
    pub fn set_error_if_exists(&mut self, error_if_exists: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_error_if_exists(self.ptr, error_if_exists as _);
        }
        self
    }

    /// If true, RocksDB will aggressively check consistency of the data.
    /// Also, if any of the  writes to the database fails (Put, Delete, Merge,
    /// Write), the database will switch to read-only mode and fail all other
    /// Write operations.
    /// In most cases you want this to be set to true.
    /// Default: true
    #[inline]
    pub fn set_paranoid_checks(&mut self, check: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_paranoid_checks(self.ptr, check as _);
        }
        self
    }

    /// Use the specified object to interact with the environment,
    /// e.g. to read/write files, schedule background work, etc.
    /// Default: Env::Default()
    #[inline]
    pub fn set_env(&mut self, env: Arc<Env>) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_env(self.ptr, env.as_mut_ptr());
        }
        // It may be unsafe to drop the old env if the options is still used for other db.
        self.env = Some(env);
        self
    }

    /// Use to control write rate of flush and compaction. Flush has higher
    /// priority than compaction. Rate limiting is disabled by default.
    /// If rate limiter is specified, bytes_per_sync is set to 1MB by default.
    ///
    /// Multiple DBs can share the same limiter.
    #[inline]
    pub fn set_rate_limiter(&mut self, limiter: &RateLimiter) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_ratelimiter(self.ptr, limiter.as_mut_ptr());
        }
        self
    }

    /// Any internal progress/error information generated by the db will
    /// be written to logger.
    ///
    /// If it is not set, the informations will be written to a file stored
    /// in the same directory as the DB contents.
    #[inline]
    pub fn set_info_log(&mut self, logger: &SysInfoLogger) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_info_log(self.ptr, logger.get());
        }
        self
    }

    /// Set the log level.
    #[inline]
    pub fn set_info_log_level(&mut self, level: LogLevel) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_info_log_level(self.ptr, level);
        }
        self
    }

    /// Number of open files that can be used by the DB.  You may need to
    /// increase this if your database has a large working set. Value -1 means
    /// files opened are always kept open. You can estimate number of files based
    /// on target_file_size_base and target_file_size_multiplier for level-based
    /// compaction. For universal-style compaction, you can usually set it to -1.
    ///
    /// Default: -1
    ///
    /// Dynamically changeable through set_db_options() API.
    #[inline]
    pub fn set_max_open_files(&mut self, max_open_files: i32) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_max_open_files(self.ptr, max_open_files);
        }
        self
    }

    /// Once write-ahead logs exceed this size, we will start forcing the flush of
    /// column families whose memtables are backed by the oldest live WAL file
    /// (i.e. the ones that are causing all the space amplification). If set to 0
    /// (default), we will dynamically choose the WAL size limit to be
    /// [sum of all write_buffer_size * max_write_buffer_number] * 4
    /// This option takes effect only when there are more than one column family as
    /// otherwise the wal size is dictated by the write_buffer_size.
    ///
    /// Default: 0
    ///
    /// Dynamically changeable through SetDBOptions() API.
    #[inline]
    pub fn set_max_total_wal_size(&mut self, size: u64) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_max_total_wal_size(self.ptr, size);
        }
        self
    }

    /// Collect metrics about database operations.
    ///
    /// Several DB can share the same statistics and they will be aggregated.
    #[inline]
    pub fn set_statistics(&mut self, statistics: &Statistics) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_statistics(self.ptr, statistics.as_mut_ptr());
        }
        self
    }

    /// By default, writes to stable storage use fdatasync (on platforms
    /// where this function is available). If this option is true,
    /// fsync is used instead.
    ///
    /// fsync and fdatasync are equally safe for our purposes and fdatasync is
    /// faster, so it is rarely necessary to set this option. It is provided
    /// as a workaround for kernel/filesystem bugs, such as one that affected
    /// fdatasync with ext4 in kernel versions prior to 3.7.
    #[inline]
    pub fn set_use_fsync(&mut self, use_fsync: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_use_fsync(self.ptr, use_fsync as _);
        }
        self
    }

    /// Paths where SST files can be put into, with its target size.
    /// Newer data is placed into paths specified earlier while
    /// older data gradually moves to paths specified later.
    ///
    /// For example, you have a flash device with 10GB allocated for the DB,
    /// as well as a hard drive of 2TB, you should config it to be:
    ///   [{"/flash_path", 10GB}, {"/hard_drive", 2TB}]
    ///
    /// The system will try to guarantee data under each path is close to but
    /// not larger than the target size. But current and future file sizes used
    /// by determining where to place a file are based on best-effort estimation,
    /// which means there is a chance that the actual size under the directory
    /// is slightly more than target size under some workloads. User should give
    /// some buffer room for those cases.
    ///
    /// If none of the paths has sufficient room to place a file, the file will
    /// be placed to the last path anyway, despite to the target size.
    ///
    /// Placing newer data to earlier paths is also best-efforts. User should
    /// expect user files to be placed in higher levels in some extreme cases.
    ///
    /// If not specified, only one path will be used, which is db_name passed when
    /// opening the DB.
    #[inline]
    pub fn add_db_path(&mut self, path: impl AsRef<Path>, target_size: u64) -> &mut Self {
        let p = path.as_ref().as_os_str().as_bytes();
        unsafe {
            tirocks_sys::crocksdb_options_add_db_paths(self.ptr, r(p), target_size);
        }
        self
    }

    /// This specifies the info LOG dir.
    /// If it is empty, the log files will be in the same dir as data.
    /// If it is non empty, the log files will be in the specified dir,
    /// and the db data dir's absolute path will be used as the log file
    /// name's prefix.
    #[inline]
    pub fn set_db_log_dir(&mut self, dir: impl AsRef<Path>) -> &mut Self {
        let p = dir.as_ref().as_os_str().as_bytes();
        unsafe {
            tirocks_sys::crocksdb_options_set_db_log_dir(self.ptr, r(p));
        }
        self
    }

    /// This specifies the absolute dir path for write-ahead logs (WAL).
    /// If it is empty, the log files will be in the same dir as data,
    ///   dbname is used as the data dir by default
    /// If it is non empty, the log files will be in kept the specified dir.
    /// When destroying the db,
    ///   all log files in wal_dir and the dir itself is deleted
    #[inline]
    pub fn set_wal_dir(&mut self, dir: impl AsRef<Path>) -> &mut Self {
        let p = dir.as_ref().as_os_str().as_bytes();
        unsafe {
            tirocks_sys::crocksdb_options_set_wal_dir(self.ptr, r(p));
        }
        self
    }

    /// The periodicity when obsolete files get deleted. The default
    /// value is 6 hours. The files that get out of scope by compaction
    /// process will still get automatically delete on every compaction,
    /// regardless of this setting. Values is wiped up to micros.
    ///
    /// Default: 6 hours
    ///
    /// Dynamically changeable through SetDBOptions() API.
    #[inline]
    pub fn set_delete_obsolete_files_period(&mut self, period: Duration) -> &mut Self {
        let micros = period.as_micros() as u64;
        unsafe {
            tirocks_sys::crocksdb_options_set_delete_obsolete_files_period_micros(self.ptr, micros);
        }
        self
    }

    /// Maximum number of concurrent background jobs (compactions and flushes).
    ///
    /// Default: 2
    ///
    /// Dynamically changeable through SetDBOptions() API.
    #[inline]
    pub fn set_max_background_jobs(&mut self, jobs: i32) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_max_background_jobs(self.ptr, jobs);
        }
        self
    }

    /// NOT SUPPORTED ANYMORE: RocksDB automatically decides this based on the
    /// value of max_background_jobs. For backwards compatibility we will set
    /// `max_background_jobs = max_background_compactions + max_background_flushes`
    /// in the case where user sets at least one of `max_background_compactions` or
    /// `max_background_flushes` (we replace -1 by 1 in case one option is unset).
    ///
    /// Maximum number of concurrent background compaction jobs, submitted to
    /// the default LOW priority thread pool.
    ///
    /// If you're increasing this, also consider increasing number of threads in
    /// LOW priority thread pool. For more information, see
    /// Env::SetBackgroundThreads
    ///
    /// Default: -1
    ///
    /// Dynamically changeable through SetDBOptions() API.
    #[deprecated]
    #[inline]
    pub fn set_max_background_compactions(&mut self, compactions: i32) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_max_background_compactions(self.ptr, compactions);
        }
        self
    }

    /// This value represents the maximum number of threads that will
    /// concurrently perform a compaction job by breaking it into multiple,
    /// smaller ones that are run simultaneously.
    /// Default: 1 (i.e. no subcompactions)
    #[inline]
    pub fn set_max_subcompactions(&mut self, compactions: u32) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_max_subcompactions(self.ptr, compactions);
        }
        self
    }

    /// NOT SUPPORTED ANYMORE: RocksDB automatically decides this based on the
    /// value of max_background_jobs. For backwards compatibility we will set
    /// `max_background_jobs = max_background_compactions + max_background_flushes`
    /// in the case where user sets at least one of `max_background_compactions` or
    /// `max_background_flushes`.
    ///
    /// Maximum number of concurrent background memtable flush jobs, submitted by
    /// default to the HIGH priority thread pool. If the HIGH priority thread pool
    /// is configured to have zero threads, flush jobs will share the LOW priority
    /// thread pool with compaction jobs.
    ///
    /// It is important to use both thread pools when the same Env is shared by
    /// multiple db instances. Without a separate pool, long running compaction
    /// jobs could potentially block memtable flush jobs of other db instances,
    /// leading to unnecessary Put stalls.
    ///
    /// If you're increasing this, also consider increasing number of threads in
    /// HIGH priority thread pool. For more information, see
    /// Env::SetBackgroundThreads
    /// Default: -1
    #[deprecated]
    #[inline]
    pub fn set_max_background_flushes(&mut self, flushes: i32) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_max_background_flushes(self.ptr, flushes);
        }
        self
    }

    /// Specify the maximal size of the info log file. If the log file
    /// is larger than `max_log_file_size`, a new info log file will
    /// be created.
    /// If max_log_file_size == 0, all logs will be written to one
    /// log file.
    #[inline]
    pub fn set_max_log_file_size(&mut self, size: usize) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_max_log_file_size(self.ptr, size);
        }
        self
    }

    /// If specified with non-zero value, log file will be rolled
    /// if it has been active longer than `log_file_time_to_roll`.
    /// `time` will be wiped up to seconds.
    #[inline]
    pub fn set_log_file_time_to_roll(&mut self, time: Duration) -> &mut Self {
        let secs = time.as_secs() as usize;
        unsafe {
            tirocks_sys::crocksdb_options_set_log_file_time_to_roll(self.ptr, secs);
        }
        self
    }

    /// Maximal info log files to be kept.
    /// Default: 1000
    #[inline]
    pub fn set_keep_log_file_num(&mut self, num: usize) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_keep_log_file_num(self.ptr, num);
        }
        self
    }

    /// Recycle log files.
    /// If non-zero, we will reuse previously written log files for new
    /// logs, overwriting the old data.  The value indicates how many
    /// such files we will keep around at any point in time for later
    /// use.  This is more efficient because the blocks are already
    /// allocated and fdatasync does not need to update the inode after
    /// each write.
    /// Default: 0
    #[inline]
    pub fn set_recycle_log_file_num(&mut self, num: usize) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_recycle_log_file_num(self.ptr, num);
        }
        self
    }

    /// manifest file is rolled over on reaching this limit.
    /// The older manifest file be deleted.
    /// The default value is 1GB so that the manifest file can grow, but not
    /// reach the limit of storage capacity.
    #[inline]
    pub fn set_max_manifest_file_size(&mut self, size: u64) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_max_manifest_file_size(self.ptr, size);
        }
        self
    }

    /// Number of shards used for table cache.
    #[inline]
    pub fn set_table_cache_num_shard_bits(&mut self, bits: i32) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_table_cache_numshardbits(self.ptr, bits);
        }
        self
    }

    /// The following two fields affect how archived logs will be deleted.
    /// 1. If both set to 0, logs will be deleted asap and will not get into
    ///    the archive.
    /// 2. If WAL_ttl is 0 and WAL_size_limit_MB is not 0,
    ///    WAL files will be checked every 10 min and if total size is greater
    ///    then WAL_size_limit_MB, they will be deleted starting with the
    ///    earliest until size_limit is met. All empty files will be deleted.
    /// 3. If WAL_ttl is not 0 and WAL_size_limit_MB is 0, then
    ///    WAL files will be checked every WAL_ttl / 2 and those that
    ///    are older than WAL_ttl will be deleted.
    /// 4. If both are not 0, WAL files will be checked every 10 min and both
    ///    checks will be performed with ttl being first.
    /// `ttl` will be wiped up to seconds.
    #[inline]
    pub fn set_wal_ttl(&mut self, ttl: Duration) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_wal_ttl_seconds(self.ptr, ttl.as_secs() as u64);
        }
        self
    }

    /// The following two fields affect how archived logs will be deleted.
    /// 1. If both set to 0, logs will be deleted asap and will not get into
    ///    the archive.
    /// 2. If WAL_ttl is 0 and WAL_size_limit_MB is not 0,
    ///    WAL files will be checked every 10 min and if total size is greater
    ///    then WAL_size_limit_MB, they will be deleted starting with the
    ///    earliest until size_limit is met. All empty files will be deleted.
    /// 3. If WAL_ttl is not 0 and WAL_size_limit_MB is 0, then
    ///    WAL files will be checked every WAL_ttl / 2 and those that
    ///    are older than WAL_ttl will be deleted.
    /// 4. If both are not 0, WAL files will be checked every 10 min and both
    ///    checks will be performed with ttl being first.
    /// `size` will be wiped up to MiB.
    #[inline]
    pub fn set_wal_size_limit(&mut self, size: u64) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_wal_size_limit_mb(self.ptr, size / 1024 / 1024);
        }
        self
    }

    /// Number of bytes to preallocate (via fallocate) the manifest
    /// files.  Default is 4mb, which is reasonable to reduce random IO
    /// as well as prevent overallocation for mounts that preallocate
    /// large amounts of data (such as xfs's allocsize option).
    #[inline]
    pub fn set_manifest_preallocation_size(&mut self, size: usize) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_manifest_preallocation_size(self.ptr, size);
        }
        self
    }

    /// Allow the OS to mmap file for reading sst tables. Default: false
    #[inline]
    pub fn set_allow_mmap_reads(&mut self, allow: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_allow_mmap_reads(self.ptr, allow as _);
        }
        self
    }

    /// Allow the OS to mmap file for writing.
    /// DB::SyncWAL() only works if this is set to false.
    /// Default: false
    #[inline]
    pub fn set_allow_mmap_write(&mut self, allow: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_allow_mmap_writes(self.ptr, allow as _);
        }
        self
    }

    /// Use O_DIRECT for user and compaction reads.
    /// When true, we also force new_table_reader_for_compaction_inputs to true.
    /// Default: false
    #[inline]
    pub fn set_use_direct_reads(&mut self, direct: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_use_direct_reads(self.ptr, direct as _);
        }
        self
    }

    /// Use O_DIRECT for writes in background flush and compactions.
    /// Default: false
    #[inline]
    pub fn set_use_direct_io_for_flush_and_compaction(&mut self, direct: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_use_direct_io_for_flush_and_compaction(
                self.ptr,
                direct as _,
            );
        }
        self
    }

    /// Disable child process inherit open files. Default: true
    #[inline]
    pub fn set_is_fd_close_on_exec(&mut self, close: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_is_fd_close_on_exec(self.ptr, close as _);
        }
        self
    }

    /// If not zero, dump rocksdb.stats to LOG every stats_dump_period_sec
    ///
    /// Default: 600 (10 min)
    ///
    /// Dynamically changeable through SetDBOptions() API.
    #[inline]
    pub fn set_stats_dump_period(&mut self, period: Duration) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_stats_dump_period_sec(
                self.ptr,
                period.as_secs() as u32,
            );
        }
        self
    }

    /// If set true, will hint the underlying file system that the file
    /// access pattern is random, when a sst file is opened.
    /// Default: true
    #[inline]
    pub fn set_advise_random_on_open(&mut self, advise: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_advise_random_on_open(self.ptr, advise as _);
        }
        self
    }

    /// Amount of data to build up in memtables across all column
    /// families before writing to disk.
    ///
    /// This is distinct from write_buffer_size, which enforces a limit
    /// for a single memtable.
    ///
    /// This feature is disabled by default. Specify a non-zero value
    /// to enable it.
    ///
    /// Default: 0 (disabled)
    #[inline]
    pub fn set_db_write_buffer_size(&mut self, size: usize) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_db_write_buffer_size(self.ptr, size);
        }
        self
    }

    /// Specify the file access pattern once a compaction is started.
    /// It will be applied to all input files of a compaction.
    /// Default: NORMAL
    #[inline]
    pub fn set_access_hint_on_compaction_start(&mut self, hint: AccessHint) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_access_hint_on_compaction_start(self.ptr, hint);
        }
        self
    }

    /// If non-zero, we perform bigger reads when doing compaction. If you're
    /// running RocksDB on spinning disks, you should set this to at least 2MB.
    /// That way RocksDB's compaction is doing sequential instead of random reads.
    ///
    /// When non-zero, we also force new_table_reader_for_compaction_inputs to
    /// true.
    ///
    /// Default: 0
    ///
    /// Dynamically changeable through SetDBOptions() API.
    #[inline]
    pub fn set_compaction_readahead_size(&mut self, size: usize) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_compaction_readahead_size(self.ptr, size);
        }
        self
    }

    /// This is the maximum buffer size that is used by WritableFileWriter.
    /// On Windows, we need to maintain an aligned buffer for writes.
    /// We allow the buffer to grow until it's size hits the limit in buffered
    /// IO and fix the buffer size when using direct IO to ensure alignment of
    /// write requests if the logical sector size is unusual
    ///
    /// Default: 1024 * 1024 (1 MB)
    ///
    /// Dynamically changeable through SetDBOptions() API.
    #[inline]
    pub fn set_writable_file_max_buffer_size(&mut self, size: usize) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_writable_file_max_buffer_size(self.ptr, size);
        }
        self
    }

    /// Use adaptive mutex, which spins in the user space before resorting
    /// to kernel. This could reduce context switch when the mutex is not
    /// heavily contended. However, if the mutex is hot, we could end up
    /// wasting spin time.
    /// Default: false
    #[inline]
    pub fn set_use_adaptive_mutex(&mut self, adaptive: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_use_adaptive_mutex(self.ptr, adaptive as _);
        }
        self
    }

    /// Allows OS to incrementally sync files to disk while they are being
    /// written, asynchronously, in the background. This operation can be used
    /// to smooth out write I/Os over time. Users shouldn't rely on it for
    /// persistency guarantee.
    /// Issue one request for every bytes_per_sync written. 0 turns it off.
    ///
    /// You may consider using rate_limiter to regulate write rate to device.
    /// When rate limiter is enabled, it automatically enables bytes_per_sync
    /// to 1MB.
    ///
    /// This option applies to table files
    ///
    /// Default: 0, turned off
    ///
    /// Note: DOES NOT apply to WAL files. See wal_bytes_per_sync instead
    /// Dynamically changeable through SetDBOptions() API.
    #[inline]
    pub fn set_bytes_per_sync(&mut self, bytes: u64) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_bytes_per_sync(self.ptr, bytes);
        }
        self
    }

    /// Same as bytes_per_sync, but applies to WAL files
    ///
    /// Default: 0, turned off
    ///
    /// Dynamically changeable through SetDBOptions() API.
    #[inline]
    pub fn set_wal_bytes_per_sync(&mut self, bytes: u64) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_wal_bytes_per_sync(self.ptr, bytes);
        }
        self
    }

    /// Add an EventListeners whose callback functions will be called
    /// when specific RocksDB event happens. Listener can be shared with multiple
    /// DBs.
    #[inline]
    pub fn add_listener(&mut self, listener: &SysEventListener) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_add_eventlistener(self.ptr, listener.get());
        }
        self
    }

    /// The limited write rate to DB if soft_pending_compaction_bytes_limit or
    /// level0_slowdown_writes_trigger is triggered, or we are writing to the
    /// last mem table allowed and we allow more than 3 mem tables. It is
    /// calculated using size of user write requests before compression.
    /// RocksDB may decide to slow down more if the compaction still
    /// gets behind further.
    /// If the value is 0, we will infer a value from `rater_limiter` value
    /// if it is not empty, or 16MB if `rater_limiter` is empty. Note that
    /// if users change the rate in `rate_limiter` after DB is opened,
    /// `delayed_write_rate` won't be adjusted.
    ///
    /// Unit: byte per second.
    ///
    /// Default: 0
    ///
    /// Dynamically changeable through SetDBOptions() API.
    #[inline]
    pub fn set_delayed_write_rate(&mut self, rate: u64) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_delayed_write_rate(self.ptr, rate);
        }
        self
    }

    /// By default, a single write thread queue is maintained. The thread gets
    /// to the head of the queue becomes write batch group leader and responsible
    /// for writing to WAL and memtable for the batch group.
    ///
    /// If enable_pipelined_write is true, separate write thread queue is
    /// maintained for WAL write and memtable write. A write thread first enter WAL
    /// writer queue and then memtable writer queue. Pending thread on the WAL
    /// writer queue thus only have to wait for previous writers to finish their
    /// WAL writing but not the memtable writing. Enabling the feature may improve
    /// write throughput and reduce latency of the prepare phase of two-phase
    /// commit.
    ///
    /// Default: false
    #[inline]
    pub fn set_enable_pipelined_write(&mut self, enable: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_enable_pipelined_write(self.ptr, enable as _);
        }
        self
    }

    /// Setting unordered_write to true trades higher write throughput with
    /// relaxing the immutability guarantee of snapshots. This violates the
    /// repeatability one expects from ::Get from a snapshot, as well as
    /// ::MultiGet and Iterator's consistent-point-in-time view property.
    /// If the application cannot tolerate the relaxed guarantees, it can implement
    /// its own mechanisms to work around that and yet benefit from the higher
    /// throughput. Using TransactionDB with WRITE_PREPARED write policy and
    /// two_write_queues=true is one way to achieve immutable snapshots despite
    /// unordered_write.
    ///
    /// By default, i.e., when it is false, rocksdb does not advance the sequence
    /// number for new snapshots unless all the writes with lower sequence numbers
    /// are already finished. This provides the immutability that we except from
    /// snapshots. Moreover, since Iterator and MultiGet internally depend on
    /// snapshots, the snapshot immutability results into Iterator and MultiGet
    /// offering consistent-point-in-time view. If set to true, although
    /// Read-Your-Own-Write property is still provided, the snapshot immutability
    /// property is relaxed: the writes issued after the snapshot is obtained (with
    /// larger sequence numbers) will be still not visible to the reads from that
    /// snapshot, however, there still might be pending writes (with lower sequence
    /// number) that will change the state visible to the snapshot after they are
    /// landed to the memtable.
    ///
    /// Default: false
    #[inline]
    pub fn set_unordered_write(&mut self, enable: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_unordered_write(self.ptr, enable as _);
        }
        self
    }

    /// By default, a single write thread queue is maintained. The thread gets
    /// to the head of the queue becomes write batch group leader and responsible
    /// for writing to WAL.
    ///
    /// If enable_pipelined_commit is true, RocksDB will apply WriteBatch to
    /// memtable out of order but commit them in order.
    ///
    /// Default: false
    #[inline]
    pub fn set_enable_pipelined_commit(&mut self, enable: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_enable_pipelined_commit(self.ptr, enable as _);
        }
        self
    }

    /// If true, allow multi-writers to update mem tables in parallel.
    /// Only some memtable_factory-s support concurrent writes; currently it
    /// is implemented only for SkipListFactory.  Concurrent memtable writes
    /// are not compatible with inplace_update_support or filter_deletes.
    /// It is strongly recommended to set enable_write_thread_adaptive_yield
    /// if you are going to use this feature.
    ///
    /// Default: true
    #[inline]
    pub fn set_allow_concurrent_memtable_write(&mut self, allow: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_allow_concurrent_memtable_write(self.ptr, allow as _);
        }
        self
    }

    /// If true, threads synchronizing with the write batch group leader will
    /// wait for up to write_thread_max_yield_usec before blocking on a mutex.
    /// This can substantially improve throughput for concurrent workloads,
    /// regardless of whether allow_concurrent_memtable_write is enabled.
    ///
    /// Default: true
    #[inline]
    pub fn set_enable_write_thread_adaptive_yield(&mut self, enable: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_enable_write_thread_adaptive_yield(
                self.ptr,
                enable as _,
            );
        }
        self
    }

    /// Recovery mode to control the consistency while replaying WAL
    /// Default: kPointInTimeRecovery
    #[inline]
    pub fn set_wal_recovery_mode(&mut self, mode: WalRecoveryMode) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_wal_recovery_mode(self.ptr, mode);
        }
        self
    }

    /// If true WAL is not flushed automatically after each write. Instead it
    /// relies on manual invocation of FlushWAL to write the WAL buffer to its
    /// file.
    #[inline]
    pub fn set_manual_wal_flush(&mut self, manual: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_manual_wal_flush(self.ptr, manual as _);
        }
        self
    }

    /// If true, RocksDB supports flushing multiple column families and committing
    /// their results atomically to MANIFEST. Note that it is not
    /// necessary to set atomic_flush to true if WAL is always enabled since WAL
    /// allows the database to be restored to the last persistent state in WAL.
    /// This option is useful when there are column families with writes NOT
    /// protected by WAL.
    /// For manual flush, application has to specify which column families to
    /// flush atomically in DB::Flush.
    /// For auto-triggered flush, RocksDB atomically flushes ALL column families.
    ///
    /// Currently, any WAL-enabled writes after atomic flush may be replayed
    /// independently if the process crashes later and tries to recover.
    #[inline]
    pub fn set_atomic_flush(&mut self, atomic: bool) -> &mut Self {
        unsafe {
            tirocks_sys::crocksdb_options_set_atomic_flush(self.ptr, atomic as _);
        }
        self
    }
}
